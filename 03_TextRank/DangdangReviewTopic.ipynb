{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import pickle\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import fasttext\n",
    "import jieba\n",
    "import jieba.posseg\n",
    "from zhon import hanzi\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset)\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tools import *\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "% matplotlib inline\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_DIR_DF = \"../01_Dataset/DandDang_review.plk\"\n",
    "FILE_PATH = \"/Users/meif/Desktop/DangdangReview\"\n",
    "\n",
    "#FILE_DIR_EMB_FAST = \"../05_Embedding/fasttext.bin\"\n",
    "#FILE_DIR_EMB_BERT = \"../05_Embedding/BERT_chinese_L-12_H-768_A-12/bert_config.json\"\n",
    "#FILE_NAME_OUTPUT = \"03_STATS/DandDang_review_book_stats.csv\"\n",
    "\n",
    "PUNCTUATIONS = \"\".join(set(hanzi.punctuation + string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADERS = [\"pid\", \"error_type\", \"comment_idx\", \"page\", \"username\", \"honor\", \"timestamp\", \"purchased\", \"support\", \"pic\", \"star\", \"comment1\", \"comment2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(FILE_DIR_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 0. Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import absolute_import, unicode_literals\n",
    "import sys\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict\n",
    "import jieba.posseg\n",
    "from jieba.analyse.tfidf import KeywordExtractor\n",
    "from jieba._compat import *\n",
    "\n",
    "\n",
    "class UndirectWeightedGraph:\n",
    "    d = 0.85\n",
    "\n",
    "    def __init__(self):\n",
    "        self.graph = defaultdict(list)\n",
    "\n",
    "    def addEdge(self, start, end, weight):\n",
    "        # use a tuple (start, end, weight) instead of a Edge object\n",
    "        self.graph[start].append((start, end, weight))\n",
    "        self.graph[end].append((end, start, weight))\n",
    "\n",
    "    def rank(self):\n",
    "        ws = defaultdict(float)\n",
    "        outSum = defaultdict(float)\n",
    "\n",
    "        wsdef = 1.0 / (len(self.graph) or 1.0)\n",
    "        for n, out in self.graph.items():\n",
    "            ws[n] = wsdef\n",
    "            outSum[n] = sum((e[2] for e in out), 0.0)\n",
    "\n",
    "        # this line for build stable iteration\n",
    "        sorted_keys = sorted(self.graph.keys())\n",
    "        for x in xrange(10):  # 10 iters\n",
    "            for n in sorted_keys:\n",
    "                s = 0\n",
    "                for e in self.graph[n]:\n",
    "                    s += e[2] / outSum[e[1]] * ws[e[1]]\n",
    "                ws[n] = (1 - self.d) + self.d * s\n",
    "\n",
    "        (min_rank, max_rank) = (sys.float_info[0], sys.float_info[3])\n",
    "\n",
    "        for w in itervalues(ws):\n",
    "            if w < min_rank:\n",
    "                min_rank = w\n",
    "            if w > max_rank:\n",
    "                max_rank = w\n",
    "\n",
    "        for n, w in ws.items():\n",
    "            # to unify the weights, don't *100.\n",
    "            ws[n] = (w - min_rank / 10.0) / (max_rank - min_rank / 10.0)\n",
    "\n",
    "        return ws\n",
    "\n",
    "\n",
    "class TextRank(KeywordExtractor):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.tokenizer = self.postokenizer = jieba.posseg.dt\n",
    "        self.stop_words = self.STOP_WORDS.copy()\n",
    "        self.pos_filt = frozenset(('ns', 'n', 'vn', 'v'))\n",
    "        self.span = 5\n",
    "\n",
    "    def pairfilter(self, wp):\n",
    "        return (wp.flag[0] in self.pos_filt and len(wp.word.strip()) >= 2\n",
    "                and wp.word.lower() not in self.stop_words)\n",
    "\n",
    "    def textrank(self, sentences, topK=20, withWeight=False, allowPOS=('ns', 'n', 'vn', 'v'), withFlag=False):\n",
    "        \"\"\"\n",
    "        Extract keywords from sentence using TextRank algorithm.\n",
    "        Parameter:\n",
    "            - topK: return how many top keywords. `None` for all possible words.\n",
    "            - withWeight: if True, return a list of (word, weight);\n",
    "                          if False, return a list of words.\n",
    "            - allowPOS: the allowed POS list eg. ['ns', 'n', 'vn', 'v'].\n",
    "                        if the POS of w is not in this list, it will be filtered.\n",
    "            - withFlag: if True, return a list of pair(word, weight) like posseg.cut\n",
    "                        if False, return a list of words\n",
    "        \"\"\"\n",
    "        self.pos_filt = frozenset(allowPOS)\n",
    "        g = UndirectWeightedGraph()\n",
    "        cm = defaultdict(int)\n",
    "        for sentence in sentences:\n",
    "            words = tuple(self.tokenizer.cut(sentence))\n",
    "            for i, wp in enumerate(words):\n",
    "                if self.pairfilter(wp):\n",
    "                    for j in xrange(i + 1, i + self.span):\n",
    "                        if j >= len(words):\n",
    "                            break\n",
    "                        if not self.pairfilter(words[j]):\n",
    "                            continue\n",
    "                        if allowPOS and withFlag:\n",
    "                            cm[(wp, words[j])] += 1\n",
    "                        else:\n",
    "                            cm[(wp.word, words[j].word)] += 1\n",
    "\n",
    "        for terms, w in cm.items():\n",
    "            g.addEdge(terms[0], terms[1], w)\n",
    "        nodes_rank = g.rank()\n",
    "        if withWeight:\n",
    "            tags = sorted(nodes_rank.items(), key=itemgetter(1), reverse=True)\n",
    "        else:\n",
    "            tags = sorted(nodes_rank, key=nodes_rank.__getitem__, reverse=True)\n",
    "\n",
    "        if topK:\n",
    "            return tags[:topK]\n",
    "        else:\n",
    "            return tags\n",
    "\n",
    "    extract_tags = textrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def remove_negation(review_list, neg_words=[\"不\", \"没\"]):\n",
    "    for i in range(len(review_list)):\n",
    "        if review_list[i].word in neg_words:\n",
    "            if i + 1 < len(review_list):\n",
    "                review_list[i+1].word = review_list[i].word + review_list[i+1].word\n",
    "            review_list[i] = \"\"\n",
    "            \n",
    "    review_list = [i for i in review_list if i != \"\"]\n",
    "    \n",
    "    return review_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 0. Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "review = data[[\"star\", \"comment1\"]]\n",
    "review[\"label\"] = 1\n",
    "review.loc[review[\"star\"] < 0.8, \"label\"] = 0\n",
    "review.drop([\"star\"], axis=1, inplace=True)\n",
    "review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meif/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/p5/bh04m0n92x1d64vgj53ntz000000gn/T/jieba.cache\n",
      "Loading model cost 0.874 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "/Users/meif/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "review[\"cut\"] = review[\"comment1\"].apply(jieba.cut).apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Save DataFrame\n",
    "\n",
    "# review.to_pickle(FILE_PATH + FILE_NAME_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Topic Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment1</th>\n",
       "      <th>label</th>\n",
       "      <th>cut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>书皮和书业之间的连接处撕开了。因为着急用没有追究。</td>\n",
       "      <td>1</td>\n",
       "      <td>[书皮, 和, 书业, 之间, 的, 连接处, 撕开, 了, 。, 因为, 着急, 用, 没...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>正版图书，值得收藏，很喜欢！</td>\n",
       "      <td>1</td>\n",
       "      <td>[正版, 图书, ，, 值得, 收藏, ，, 很, 喜欢, ！]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>书皮与中间部分脱落损坏</td>\n",
       "      <td>1</td>\n",
       "      <td>[书皮, 与, 中间, 部分, 脱落, 损坏]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>很不错的书</td>\n",
       "      <td>1</td>\n",
       "      <td>[很, 不错, 的, 书]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>书不错，但打开书就烂成这样</td>\n",
       "      <td>0</td>\n",
       "      <td>[书, 不错, ，, 但, 打开, 书, 就, 烂成, 这样]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>非常好，值得收藏</td>\n",
       "      <td>1</td>\n",
       "      <td>[非常, 好, ，, 值得, 收藏]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>给老公买的书，正版书，发货速度很快，老公很满意书的质量。</td>\n",
       "      <td>1</td>\n",
       "      <td>[给, 老公, 买, 的, 书, ，, 正版书, ，, 发货, 速度, 很快, ，, 老公,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>书，非常非常快地送达；包装非常非常的严实，书籍完好无损。 至于，书的内容，说“完美”可以吗，...</td>\n",
       "      <td>1</td>\n",
       "      <td>[书, ，, 非常, 非常, 快地, 送达, ；, 包装, 非常, 非常, 的, 严实, ，...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>一本本买，预备集齐一套</td>\n",
       "      <td>1</td>\n",
       "      <td>[一本, 本买, ，, 预备, 集齐, 一套]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>没有塑料包装，封面有很多灰</td>\n",
       "      <td>1</td>\n",
       "      <td>[没有, 塑料包装, ，, 封面, 有, 很多, 灰]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>好</td>\n",
       "      <td>1</td>\n",
       "      <td>[好]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>为什么不给发票呀</td>\n",
       "      <td>1</td>\n",
       "      <td>[为什么, 不, 给, 发票, 呀]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>不懂的。</td>\n",
       "      <td>1</td>\n",
       "      <td>[不, 懂, 的, 。]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>服务好，送货快</td>\n",
       "      <td>1</td>\n",
       "      <td>[服务, 好, ，, 送货, 快]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>不错，好评！</td>\n",
       "      <td>1</td>\n",
       "      <td>[不错, ，, 好评, ！]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>还不错，很好，值得去读。</td>\n",
       "      <td>1</td>\n",
       "      <td>[还, 不错, ，, 很, 好, ，, 值得, 去, 读, 。]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>henxiangxi,kaoshideshihoumaide</td>\n",
       "      <td>1</td>\n",
       "      <td>[henxiangxi, ,, kaoshideshihoumaide]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>非常满意，正品书。当当送货快，包装好，服务态度很棒。</td>\n",
       "      <td>1</td>\n",
       "      <td>[非常, 满意, ，, 正品, 书, 。, 当当, 送货, 快, ，, 包装, 好, ，, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>挺好的</td>\n",
       "      <td>1</td>\n",
       "      <td>[挺, 好, 的]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>快递很快，正品书，满意！</td>\n",
       "      <td>1</td>\n",
       "      <td>[快递, 很快, ，, 正品, 书, ，, 满意, ！]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment1  label  \\\n",
       "0                           书皮和书业之间的连接处撕开了。因为着急用没有追究。      1   \n",
       "1                                      正版图书，值得收藏，很喜欢！      1   \n",
       "2                                         书皮与中间部分脱落损坏      1   \n",
       "3                                               很不错的书      1   \n",
       "4                                       书不错，但打开书就烂成这样      0   \n",
       "5                                            非常好，值得收藏      1   \n",
       "6                        给老公买的书，正版书，发货速度很快，老公很满意书的质量。      1   \n",
       "7   书，非常非常快地送达；包装非常非常的严实，书籍完好无损。 至于，书的内容，说“完美”可以吗，...      1   \n",
       "8                                         一本本买，预备集齐一套      1   \n",
       "9                                       没有塑料包装，封面有很多灰      1   \n",
       "10                                                  好      1   \n",
       "11                                           为什么不给发票呀      1   \n",
       "12                                               不懂的。      1   \n",
       "13                                            服务好，送货快      1   \n",
       "14                                             不错，好评！      1   \n",
       "15                                       还不错，很好，值得去读。      1   \n",
       "16                     henxiangxi,kaoshideshihoumaide      1   \n",
       "17                         非常满意，正品书。当当送货快，包装好，服务态度很棒。      1   \n",
       "18                                                挺好的      1   \n",
       "19                                       快递很快，正品书，满意！      1   \n",
       "\n",
       "                                                  cut  \n",
       "0   [书皮, 和, 书业, 之间, 的, 连接处, 撕开, 了, 。, 因为, 着急, 用, 没...  \n",
       "1                    [正版, 图书, ，, 值得, 收藏, ，, 很, 喜欢, ！]  \n",
       "2                             [书皮, 与, 中间, 部分, 脱落, 损坏]  \n",
       "3                                       [很, 不错, 的, 书]  \n",
       "4                     [书, 不错, ，, 但, 打开, 书, 就, 烂成, 这样]  \n",
       "5                                  [非常, 好, ，, 值得, 收藏]  \n",
       "6   [给, 老公, 买, 的, 书, ，, 正版书, ，, 发货, 速度, 很快, ，, 老公,...  \n",
       "7   [书, ，, 非常, 非常, 快地, 送达, ；, 包装, 非常, 非常, 的, 严实, ，...  \n",
       "8                             [一本, 本买, ，, 预备, 集齐, 一套]  \n",
       "9                         [没有, 塑料包装, ，, 封面, 有, 很多, 灰]  \n",
       "10                                                [好]  \n",
       "11                                 [为什么, 不, 给, 发票, 呀]  \n",
       "12                                       [不, 懂, 的, 。]  \n",
       "13                                  [服务, 好, ，, 送货, 快]  \n",
       "14                                     [不错, ，, 好评, ！]  \n",
       "15                   [还, 不错, ，, 很, 好, ，, 值得, 去, 读, 。]  \n",
       "16               [henxiangxi, ,, kaoshideshihoumaide]  \n",
       "17  [非常, 满意, ，, 正品, 书, 。, 当当, 送货, 快, ，, 包装, 好, ，, ...  \n",
       "18                                          [挺, 好, 的]  \n",
       "19                       [快递, 很快, ，, 正品, 书, ，, 满意, ！]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_str_neg = data[data[\"label\"] == 0][\"comment1\"].apply(lambda x:re.split(r'[.。!！?？,，]', x))\n",
    "review_str_pos = data[data[\"label\"] == 1][\"comment1\"].apply(lambda x:re.split(r'[.。!！?？,，]', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_str_neg = [i for j in review_str_neg.tolist() for i in j if i.strip() != \"\"]\n",
    "review_str_pos = [i for j in review_str_pos.tolist() for i in j if i.strip() != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "DEBUG:jieba:Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/p5/bh04m0n92x1d64vgj53ntz000000gn/T/jieba.cache\n",
      "DEBUG:jieba:Dumping model to file cache /var/folders/p5/bh04m0n92x1d64vgj53ntz000000gn/T/jieba.cache\n",
      "Loading model cost 1.187 seconds.\n",
      "DEBUG:jieba:Loading model cost 1.187 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "DEBUG:jieba:Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v 没有 1.0\n",
      "n 内容 0.6129604671275753\n",
      "n 感觉 0.3634818558385292\n",
      "n 孩子 0.36324876969222375\n",
      "n 有点 0.278767505992373\n",
      "n 作者 0.272526566192268\n",
      "v 喜欢 0.2606507982905845\n",
      "v 快递 0.2573736223730701\n",
      "v 包装 0.22404458419515275\n",
      "n 问题 0.2094211312745656\n",
      "v 觉得 0.20730922883178962\n",
      "v 知道 0.20539959992120563\n",
      "v 适合 0.2036042149522953\n",
      "n 故事 0.19251160643287257\n",
      "vn 印刷 0.19092061172468133\n",
      "n 时候 0.19047860597063518\n",
      "n 质量 0.1856154610483309\n",
      "n 客服 0.17798470141554712\n",
      "v 不能 0.17359393041179716\n",
      "v 应该 0.16746485964082136\n",
      "v 阅读 0.16639172326004406\n",
      "v 还有 0.16295431601681606\n",
      "v 学习 0.14272274113599\n",
      "v 发现 0.14236692497915\n",
      "ns 中国 0.14159715268491327\n",
      "v 希望 0.14058303366221697\n",
      "v 收到 0.13365878225715114\n",
      "v 翻译 0.13232985310806097\n",
      "n 封面 0.131683805991546\n",
      "n 评论 0.13107243213766842\n",
      "v 看到 0.12042073191313064\n",
      "v 介绍 0.12006036598868458\n",
      "v 可能 0.1184898215759818\n",
      "ns 东西 0.11821236098927249\n",
      "n 纸张 0.11702425575794775\n",
      "v 需要 0.11678314102848424\n",
      "v 推荐 0.1078202049958158\n",
      "v 购买 0.10541861888060448\n",
      "v 作为 0.10510505973978797\n",
      "n 时间 0.10409392162387116\n",
      "n 结果 0.10399099907519581\n",
      "n 物流 0.1039096563875432\n",
      "n 老师 0.10329369123162654\n",
      "n 部分 0.10193645260513268\n",
      "v 了解 0.10001003143592452\n",
      "n 纸质 0.09724688097950655\n",
      "n 建议 0.09606724795858566\n",
      "vn 教育 0.09407207717133023\n",
      "n 历史 0.09394302202044719\n",
      "n 书籍 0.09317064989399616\n",
      "n 文字 0.09278922636418845\n",
      "n 读者 0.0911957492457013\n",
      "v 看看 0.08830950992776132\n",
      "v 实在 0.08819915805118048\n",
      "n 地方 0.08758894336457052\n",
      "n 联系 0.08674556235795183\n",
      "n 个人 0.08469252792713777\n",
      "n 大家 0.08328194991805425\n",
      "v 只能 0.08284980420929701\n",
      "v 不会 0.08235361785192495\n",
      "v 出来 0.08199692405203184\n",
      "v 开始 0.08092719718845798\n",
      "v 不够 0.08065228849318166\n",
      "n 图片 0.0796625032497071\n",
      "n 学生 0.07880960030466178\n",
      "v 盗版 0.07824197682864371\n",
      "n 出版社 0.07812779308039641\n",
      "n 作品 0.0778794647613069\n",
      "vn 生活 0.07646177981812043\n",
      "n 版本 0.07626020330959529\n",
      "v 展开 0.07558916051690416\n",
      "v 理解 0.0755556429301972\n",
      "v 值得 0.07506144790855011\n",
      "n 基本 0.07343256854905102\n",
      "v 起来 0.07340567039006514\n",
      "n 发货 0.0733387010711287\n",
      "v 当当网 0.07201206333455495\n",
      "n 小说 0.07178778686355052\n",
      "n 错误 0.07010503900079473\n",
      "v 破损 0.06998732458121924\n",
      "v 知识 0.06866295599174985\n",
      "v 失望 0.06713858646600794\n",
      "v 帮助 0.06706251580294122\n",
      "vn 影响 0.06630007706076622\n",
      "vn 研究 0.0643844433803287\n",
      "n 方法 0.06398139374581693\n",
      "v 出现 0.0635897116763945\n",
      "n 教学 0.06268275387466601\n",
      "n 光盘 0.0625023444548182\n",
      "v 要求 0.06237751124303282\n",
      "n 书本 0.06226192554980441\n",
      "vn 活动 0.06209039175281672\n",
      "n 经典 0.06199482819464187\n",
      "n 教师 0.06179147018249051\n",
      "n 基础 0.06107162550982285\n",
      "v 看着 0.0599210742484371\n",
      "v 出版 0.058617448852322326\n",
      "n 商品 0.058260588101193216\n",
      "n 公司 0.057887478920701424\n",
      "n 无法 0.0578309561552544\n",
      "n 方面 0.05683312927722906\n",
      "n 教材 0.056826729685041766\n",
      "v 退货 0.056670789198838376\n",
      "n 电话 0.05601982153125425\n",
      "n 评价 0.05569862511199753\n",
      "v 进行 0.05521073846518808\n",
      "n 价格 0.055165632345030115\n",
      "n 过程 0.05497998328653245\n",
      "n 答案 0.05451386720956484\n",
      "v 选择 0.05434148825298198\n",
      "v 排版 0.054024566228269816\n",
      "n 专业 0.053320924478617145\n",
      "vn 设计 0.05331082309637893\n",
      "n 世界 0.053103834752360156\n",
      "n 理论 0.05275503740314195\n",
      "v 显示 0.05206032792667955\n",
      "vn 工作 0.05198578945679235\n",
      "v 使用 0.05179493049767548\n",
      "n 学校 0.05125637233947213\n",
      "v 像是 0.05094577499115234\n",
      "n 方式 0.050885040408584804\n",
      "v 解释 0.050786072677102265\n",
      "n 文化 0.05007686033040898\n",
      "v 打开 0.05003186612593554\n",
      "n 朋友 0.05000736525177839\n",
      "n 文章 0.04974183392643034\n",
      "n 先生 0.04921558786736512\n",
      "n 语言 0.04909094250760437\n",
      "v 不到 0.04858518886909954\n",
      "v 讲解 0.04856571137946245\n",
      "n 水平 0.048565466727979345\n",
      "v 看过 0.04830473294988633\n",
      "vn 分析 0.047752442551313924\n",
      "vn 服务 0.04708584845428382\n",
      "v 不了 0.047020583487017896\n",
      "v 好像 0.04697550907502824\n",
      "n 案例 0.046974154638303844\n",
      "v 正版 0.04664954291800371\n",
      "n 字体 0.04660731053610367\n",
      "nz 英语 0.046386502159693206\n",
      "n 图书 0.045920460122086476\n",
      "n 情况 0.04523620134717172\n",
      "v 拿到 0.045063133928292844\n",
      "n 思想 0.04503571429965515\n",
      "n 想象 0.044836569162597394\n",
      "v 才能 0.044254933877672965\n",
      "n 态度 0.043830684813164725\n",
      "v 写作 0.04321865136215391\n",
      "n 人物 0.04321192515764753\n",
      "v 比如 0.04289502168462415\n",
      "n 信息 0.042558989410888995\n",
      "n 套书 0.042540926599266796\n",
      "n 发票 0.04240278897087768\n",
      "n 速度 0.042071128796608556\n",
      "n 社会 0.04187440771751814\n",
      "n 实际 0.041794510987975084\n",
      "v 买来 0.04178592068725647\n",
      "n 原因 0.04154125147717253\n",
      "v 认为 0.04096327678358011\n",
      "ns 日本 0.04016631420555703\n",
      "v 还好 0.03867665461120085\n",
      "v 说明 0.03816783625723633\n",
      "n 视频 0.03806081219268502\n",
      "v 能够 0.03802102689170674\n",
      "n 系统 0.03775419723198686\n",
      "n 观点 0.03767392980965025\n",
      "vn 发展 0.03742785727289215\n",
      "v 收藏 0.037137228196406684\n",
      "v 怀疑 0.03699387672989883\n",
      "n 价值 0.036841847180632374\n",
      "v 提供 0.03682936561192356\n",
      "n 体验 0.036795065838271086\n",
      "v 看起来 0.03672632928765316\n",
      "v 好看 0.03667933322607567\n",
      "v 描述 0.0366348402579978\n",
      "v 处理 0.03658742168860183\n",
      "vn 管理 0.036277673543380344\n",
      "n 商家 0.036243188413110645\n",
      "v 是否 0.03579392298954133\n",
      "v 装订 0.03541046706914078\n",
      "n 小朋友 0.03517459782449142\n",
      "n 购物 0.0350781029047144\n",
      "ns 美国 0.03499137855125538\n"
     ]
    }
   ],
   "source": [
    "tmp = TextRank().textrank(sentences=review_str_neg, topK=200, withWeight=True, allowPOS=('n', 'v', 'a'))\n",
    "\n",
    "textrank_res_neg = {'n':[], 'v':[], 'a':[]}\n",
    "for x, w in tmp:\n",
    "    x = list(jieba.posseg.dt.cut(x))[0]\n",
    "    textrank_res_neg[x.flag[0]] = textrank_res_neg.get(x.flag[0], []) + [(x.word, w)]\n",
    "    if x.flag[0] in ['n', 'v']:\n",
    "        print('{} {} {}'.format(x.flag, x.word, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < len(textrank_res_neg['v']):\n",
    "    if textrank_res_neg['v'][i][0] in [\"快递\", \"包装\", \"印刷\", \"翻译\", \"装订\", \"排版\", \"设计\", \"服务\"]:\n",
    "        textrank_res_neg['n'].append(textrank_res_neg['v'][i])\n",
    "        textrank_res_neg['v'].remove(textrank_res_neg['v'][i])\n",
    "        i -= 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FILE_PATH + '/03_Analysis/textrank_res_neg.json', 'w') as f:\n",
    "    json.dump(textrank_res_neg, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n 孩子 1.0\n",
      "v 喜欢 0.7436403077951036\n",
      "n 内容 0.38397189763491546\n",
      "v 没有 0.37133603355348965\n",
      "v 阅读 0.29205498522459944\n",
      "n 故事 0.2819938183420397\n",
      "v 学习 0.2558667738738034\n",
      "v 值得 0.2503734387219766\n",
      "v 推荐 0.24468429439660208\n",
      "n 感觉 0.21355276489094258\n",
      "n 老师 0.21256824241796737\n",
      "n 作者 0.21247668792195443\n",
      "v 适合 0.21168711664842266\n",
      "ns 中国 0.19916837578385282\n",
      "v 希望 0.19450597898886932\n",
      "vn 生活 0.17645431965571776\n",
      "n 时候 0.17369161789246665\n",
      "v 帮助 0.16530090631566755\n",
      "n 历史 0.16184550825229727\n",
      "v 觉得 0.15513808357369394\n",
      "n 经典 0.14808096912373853\n",
      "v 了解 0.14735631087589798\n",
      "v 看到 0.1433916435066556\n",
      "n 作品 0.1378996350902723\n",
      "v 知道 0.13739410515470907\n",
      "v 还有 0.13423103745941364\n",
      "v 应该 0.1296363137784832\n",
      "n 质量 0.12961014747214653\n",
      "n 世界 0.12890555280412508\n",
      "n 评论 0.12772415886327604\n",
      "n 有点 0.12242184595340277\n",
      "v 知识 0.11919825404808175\n",
      "v 包装 0.11872486161382446\n",
      "v 开始 0.11857368322032424\n",
      "n 朋友 0.11456436082448272\n",
      "n 小说 0.11402212847916295\n",
      "v 购买 0.11397283573968636\n",
      "v 需要 0.11313698195052799\n",
      "n 先生 0.11198474463353361\n",
      "vn 印刷 0.11113169235413216\n",
      "n 问题 0.10584415919687461\n",
      "n 文字 0.10387819779022911\n",
      "n 书籍 0.10203718069566611\n",
      "n 时间 0.1011702028778666\n",
      "v 作为 0.09899965661518113\n",
      "n 好书 0.09737689314049341\n",
      "n 文化 0.08844460903496751\n",
      "n 人生 0.08814424831459025\n",
      "n 儿子 0.0868215365810993\n",
      "vn 活动 0.085420824069946\n",
      "nz 英语 0.08229718852881303\n",
      "v 展开 0.08172109236262785\n",
      "v 起来 0.08139542323178921\n",
      "v 理解 0.08130219063831139\n",
      "n 大家 0.08076002781310776\n",
      "ns 东西 0.0793452080291535\n",
      "n 读者 0.07861343122627634\n",
      "v 看看 0.0783767984016029\n",
      "v 发现 0.07759242940436731\n",
      "v 介绍 0.07733175644098865\n",
      "nr 宝宝 0.07667374407874772\n",
      "v 不能 0.07642432725861599\n",
      "n 社会 0.07537339991526242\n",
      "v 快递 0.07509046610921954\n",
      "n 套书 0.07446466130449497\n",
      "vn 研究 0.0736701851948003\n",
      "v 可能 0.07231350247131002\n",
      "v 不会 0.07198993343881988\n",
      "n 小朋友 0.07143676017722636\n",
      "v 收藏 0.07132527901645726\n",
      "v 能够 0.07012832586462826\n",
      "n 读书 0.06935059001582486\n",
      "n 方法 0.06900722047563827\n",
      "vn 教育 0.06740831393924752\n",
      "n 图书 0.06480056741730236\n",
      "n 语言 0.06408955144362687\n",
      "n 版本 0.06368784039442162\n",
      "v 成为 0.0636211801885836\n",
      "v 提高 0.06339185692216831\n",
      "n 人物 0.06288449760857721\n",
      "v 实用 0.06287995779099877\n",
      "n 学生 0.06260769152614037\n",
      "n 绘本 0.06218925931844753\n",
      "v 看过 0.06128077670182833\n",
      "v 好看 0.061111992231096014\n",
      "v 出版 0.06072111446457662\n",
      "v 进行 0.06041061473497303\n",
      "n 全面 0.060347213020985384\n",
      "n 方式 0.06018364175103755\n",
      "n 女儿 0.059992244728768115\n",
      "n 教材 0.05956563797198039\n",
      "n 学校 0.05917732264812152\n",
      "v 买来 0.058928578825869174\n",
      "n 方面 0.05863934277768222\n",
      "n 封面 0.05789227623946436\n",
      "n 思想 0.05707742270240245\n",
      "n 能力 0.05667543966815222\n",
      "n 物流 0.05660190409576496\n",
      "v 满意 0.056430222734908386\n",
      "n 纸张 0.0562839822736782\n",
      "vn 发展 0.05603573681512675\n",
      "vn 工作 0.05515709573826003\n",
      "v 翻译 0.055023442061204096\n",
      "v 收到 0.05442523600148046\n",
      "n 基础 0.05428351704936338\n",
      "n 商品 0.05354735124723587\n",
      "n 过程 0.053405764965317716\n",
      "n 大师 0.05329711872345643\n",
      "ns 日本 0.05300264811054317\n",
      "n 速度 0.05164574604091426\n",
      "n 文学 0.05148261995945638\n",
      "n 整体 0.05145705847437804\n",
      "v 出来 0.05134430550753935\n",
      "ns 美国 0.05050872394290486\n",
      "n 妈妈 0.05049906495979031\n",
      "n 个人 0.05040026283389079\n",
      "n 时代 0.050271244164262936\n",
      "vn 生命 0.0501630785548449\n",
      "v 成长 0.049950438589489235\n",
      "n 出版社 0.04969929896029131\n",
      "n 动物 0.04931460502167843\n",
      "n 部分 0.04899869594998286\n",
      "n 思维 0.04795001727983192\n",
      "n 作家 0.04769608052111987\n",
      "v 要求 0.04753689446731306\n",
      "n 纸质 0.047302039144941015\n",
      "v 才能 0.04705663219425231\n",
      "vn 设计 0.04695465722152368\n",
      "n 小孩 0.04676680086968979\n",
      "n 数学 0.04669155590502416\n",
      "v 选择 0.046516827446061546\n",
      "n 人类 0.04646950266454161\n",
      "v 讲解 0.04640655911213028\n",
      "n 地方 0.04625059503817295\n",
      "vn 分析 0.04578881493772192\n",
      "v 看着 0.045772185272570876\n",
      "n 家长 0.04523287077731223\n",
      "n 价格 0.044577547836368935\n",
      "n 精神 0.0440883334229927\n",
      "v 当当网 0.043668301925312285\n",
      "v 讲述 0.04345656754527289\n",
      "vn 影响 0.04335441404204881\n",
      "n 经历 0.043208817277078364\n",
      "n 文章 0.04314877587556607\n",
      "n 爱情 0.042533391632901124\n",
      "n 兴趣 0.04247999854134979\n",
      "v 正版 0.04247648538091777\n",
      "v 吸引 0.042200974629644034\n",
      "n 传统 0.042029514166167625\n",
      "n 专业 0.04167621736343678\n",
      "v 使用 0.04157301677956608\n",
      "v 认识 0.04116224578643947\n",
      "v 思考 0.040774138758847604\n",
      "n 理论 0.04049120605686276\n",
      "n 基本 0.040082439334762535\n",
      "n 人们 0.04003172822419343\n",
      "v 培养 0.03998496322856418\n",
      "v 拥有 0.039971652301894096\n",
      "v 练习 0.0396058016062297\n",
      "n 评价 0.03936732142065772\n",
      "n 儿童 0.039260267898396255\n",
      "v 感受 0.038985354592076804\n",
      "v 继续 0.038719483456860146\n",
      "v 准备 0.03859329589193064\n",
      "v 写作 0.038574550842235156\n",
      "n 心理 0.038506840123761946\n",
      "n 小学 0.03775261502586427\n",
      "n 风格 0.03764639172547073\n",
      "n 艺术 0.03644533909771597\n",
      "v 找到 0.036366047092386077\n",
      "n 无法 0.036314786319387705\n",
      "n 漫画 0.03577272373557616\n",
      "nr 智慧 0.03575166443786719\n",
      "n 国家 0.035642235552467885\n",
      "v 认为 0.03559246377930592\n",
      "n 书本 0.035561236123593847\n",
      "v 必读 0.0354642228581099\n",
      "n 科学 0.035418751248408646\n",
      "v 得到 0.035226431486233035\n",
      "n 精彩 0.03501406649606746\n",
      "n 电影 0.03468090909920125\n",
      "n 建议 0.034577926657676276\n"
     ]
    }
   ],
   "source": [
    "tmp = TextRank().textrank(sentences=review_str_pos, topK=200, withWeight=True, allowPOS=('n', 'v', 'a'))\n",
    "\n",
    "textrank_res_pos = {'n':[], 'v':[], 'a':[]}\n",
    "for x, w in tmp:\n",
    "    x = list(jieba.posseg.dt.cut(x))[0]\n",
    "    textrank_res_pos[x.flag[0]] = textrank_res_pos.get(x.flag[0], []) + [(x.word, w)]\n",
    "    if x.flag[0] in ['n', 'v']:\n",
    "        print('{} {} {}'.format(x.flag, x.word, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < len(textrank_res_pos['v']):\n",
    "    if textrank_res_pos['v'][i][0] in [\"快递\", \"包装\", \"印刷\", \"翻译\", \"装订\", \"排版\", \"设计\", \"服务\"]:\n",
    "        textrank_res_pos['n'].append(textrank_res_pos['v'][i])\n",
    "        textrank_res_pos['v'].remove(textrank_res_pos['v'][i])\n",
    "        i -= 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(FILE_PATH + '/03_Analysis/textrank_res_pos.json', 'w') as f:\n",
    "    json.dump(textrank_res_pos, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_cut_neg = data.loc[data[\"label\"] == 0, \"cut\"]\n",
    "review_cut_pos = data.loc[data[\"label\"] == 1, \"cut\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_cut_neg = [i for j in review_cut_neg.tolist() for i in j]\n",
    "review_cut_pos = [i for j in review_cut_pos.tolist() for i in j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_cut_neg = \" \".join(review_cut_neg)\n",
    "review_cut_pos = \" \".join(review_cut_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000,\n",
    "                             min_df=2, stop_words=None)\n",
    "X = vectorizer.fit_transform([review_cut_neg, review_cut_pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_array = np.array(vectorizer.get_feature_names())\n",
    "tfidf_sorting_1 = np.argsort(X[0].toarray()).flatten()[::-1]\n",
    "tfidf_sorting_2 = np.argsort(X[1].toarray()).flatten()[::-1]\n",
    "\n",
    "n = 100\n",
    "top_n_1 = feature_array[tfidf_sorting_1][:n]\n",
    "top_n_2 = feature_array[tfidf_sorting_2][:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TOPIC_LIST = {\n",
    "    '品质': ['质量', '错误', '正版', '盗版'],\n",
    "    '功能': ['内容', '作者', '故事', '版本', '光盘', '翻译'],\n",
    "    '价格': ['价格', '价钱'],\n",
    "    '设计': ['包装', '封面', '装订', '设计', '书皮'], \n",
    "    '使用': ['印刷', '书页', '纸张', '纸质', '图片', '出版社', '字体', '排版', '边切', '边线'],\n",
    "    '服务': ['客服', '电话', '态度', '服务', '发票', '退货', '换货', '退款', '手续', \n",
    "            '物流', '配送', '送货', '时间', '发货', '快递', '速度', '调货', '出仓']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
